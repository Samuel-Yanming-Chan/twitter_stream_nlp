{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "import json\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from twython import TwythonStreamer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Gene's TwythonStreamer \n",
    "\n",
    "# Acknowledgement: This code is adopted from the book \"Data Science from Scratch\"\n",
    "# https://github.com/joelgrus/data-science-from-scratch/tree/master/first-edition\n",
    "class MyStreamer(TwythonStreamer):\n",
    "\n",
    "    # by default, this module will collect 1000 tweets\n",
    "    target_tweet_count = 1000\n",
    "    \n",
    "    # overriding\n",
    "    def on_success(self, data):\n",
    "        if 'text' in data:      # check if the received data has key 'text'\n",
    "            tweets.append(data) # append data to our list\n",
    "            \n",
    "        if len(tweets) % 100 == 1:\n",
    "            print('\\nNow we collected {} tweets!'.format(len(tweets)))\n",
    "            print(len(tweets), data['text'])    # print the tweet text\n",
    "\n",
    "        if len(tweets) >= self.target_tweet_count:  # if we have 1000 tweets\n",
    "            self.disconnect()   # disconnect API connection using a method from TwythonStreamer\n",
    "\n",
    "    # overriding\n",
    "    def on_error(self, status_code, data):\n",
    "        print(status_code)\n",
    "        self.disconnect()\n",
    "\n",
    "# global list to collect the tweets\n",
    "tweets = []       \n",
    "\n",
    "def collect_tweets(stream, keyword, count):\n",
    "    global tweets\n",
    "    tweets = [] # re-initialize tweets list\n",
    "    stream.target_tweet_count = count\n",
    "    stream.statuses.filter(track=keyword)\n",
    "    return tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import credentials from env vars\n",
    "consumer_key = str(os.environ['twit_consumer_key'])\n",
    "consumer_secret = str(os.environ['twit_consumer_secret'])\n",
    "access_token = str(os.environ['twit_access_token'])\n",
    "access_token_secret = str(os.environ['twit_access_token_secret'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyStreamer object at 0x000001F1285C7160>\n"
     ]
    }
   ],
   "source": [
    "#Create Stream\n",
    "stream = MyStreamer(consumer_key, consumer_secret, access_token, access_token_secret)\n",
    "print(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keyword = 'Boris Johnson'\n",
    "# #keyword = ''\n",
    "# print('My keywords is ' + keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start collecting 5000 tweets with keyword\n",
    "# tweets = collect_tweets(stream, keyword, 5000)\n",
    "# print(len(tweets), 'tweets are collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tweet_stream_{}_{}.json'.format(keyword, len(tweets)), 'w') as outfile:\n",
    "#     json.dump(tweets, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My keywords is Brexit\n"
     ]
    }
   ],
   "source": [
    "keyword = 'Brexit'\n",
    "#keyword = ''\n",
    "print('My keywords is ' + keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Now we collected 1 tweets!\n",
      "1 RT @nickreeves9876: If Brexit happens it will be the first time in over 300 years that a hostile foreign power has successfully manipulated…\n",
      "\n",
      "Now we collected 101 tweets!\n",
      "101 RT @ActionWalsall: I was pretty ambivalent about EU until Brexit fever started, I’m fully in favour of remaining at the top table and tryin…\n",
      "\n",
      "Now we collected 201 tweets!\n",
      "201 RT @nyeannebevan: Now this is an interesting little article from the brilliant @skwawkbox back in February...about (ahem) *Opinium* CEO Jam…\n",
      "\n",
      "Now we collected 301 tweets!\n",
      "301 @BrookMatthew Hi, just a reminder that Brexit has not happened yet. It is due to occur on the 29th March 2019\n",
      "\n",
      "Now we collected 401 tweets!\n",
      "401 RT @grahambsi: For heavens sake @UKLabour and @LibDems voters get over yourselves. Vote tactically or have years to regret it in Brexit Bri…\n",
      "\n",
      "Now we collected 501 tweets!\n",
      "501 RT @jeremycorbyn: As Prime Minister, I will be an honest broker and not campaign for either side in the final say referendum. We will negot…\n",
      "\n",
      "Now we collected 601 tweets!\n",
      "601 RT @TheDA_UK: Dr David Nicholl @djnicholl is a consultant neurologist who spoke up on the shortages of vital medications with a no-deal Bre…\n",
      "\n",
      "Now we collected 701 tweets!\n",
      "701 RT @OwenJones84: If you’re voting for the Lib Dems in a Labour-Tory marginal now, you might as well vote for Boris Johnson, Hard Brexit and…\n",
      "\n",
      "Now we collected 801 tweets!\n",
      "801 RT @HackedOffHugh: I feel I need to retweet my own retweet.  The Americans can see clearly what’s happening here.  Johnson is Putin’s asset…\n",
      "\n",
      "Now we collected 901 tweets!\n",
      "901 RT @SadiqKhan: Londoners face a choice between Boris Johnson's Brexit-backing, austerity loving Tory Party and Labour - who will give the p…\n",
      "\n",
      "Now we collected 1001 tweets!\n",
      "1001 RT @charlievg77: Anyone with lingering doubts about #Russia interference in #brexit should watch this. Laid bare by US authorities. @TheAnd…\n",
      "\n",
      "Now we collected 1101 tweets!\n",
      "1101 RT @EmmaKennedy: I am BEGGING you Labour, there are around 60 seats across SE where the only contenders are the LDs. \n",
      "\n",
      "PLEASE urge your sup…\n",
      "\n",
      "Now we collected 1201 tweets!\n",
      "1201 RT @meadwaj: Trust No Polls. This, categorically, is an outlier, at odds with any other evidence we have. Two million registrations to vote…\n"
     ]
    }
   ],
   "source": [
    "# start collecting 5000 tweets with keyword\n",
    "tweets = collect_tweets(stream, keyword, 5000)\n",
    "print(len(tweets), 'tweets are collected')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_stream_{}_{}.json'.format(keyword, len(tweets)), 'w') as outfile:\n",
    "    json.dump(tweets, outfile, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open files \n",
    "with open('tweet_stream_Brexit_5000.json') as infile:\n",
    "    brex_data = json.load(infile)\n",
    "    \n",
    "with open('tweet_stream_Boris_Johnson_5000.json') as infile:\n",
    "    bj_data = json.load(infile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
